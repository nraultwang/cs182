{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0tEWeXXMQQvH"
   },
   "source": [
    "## The power of the graph perspective in clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5FAqlqcFQQvH"
   },
   "source": [
    "#### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1610,
     "status": "ok",
     "timestamp": 1664304108170,
     "user": {
      "displayName": "Jerome Quenum",
      "userId": "13777372482022053047"
     },
     "user_tz": 420
    },
    "id": "Av-iNF_AQQvI"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "from scipy.linalg import svd\n",
    "from scipy.spatial import distance\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QceEeGGwQQvJ"
   },
   "source": [
    "#### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1664304108171,
     "user": {
      "displayName": "Jerome Quenum",
      "userId": "13777372482022053047"
     },
     "user_tz": 420
    },
    "id": "Df2UZpccQQvJ"
   },
   "outputs": [],
   "source": [
    "def get_data(n_samples, seed):\n",
    "    T_matrix = [[-0.60834549, -0.63667341], [0.40887718, 0.85253229]]\n",
    "    X_orig, y_orig = make_blobs(n_samples=n_samples, random_state=170)\n",
    "    X = np.dot(X_orig, T_matrix)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1664304108171,
     "user": {
      "displayName": "Jerome Quenum",
      "userId": "13777372482022053047"
     },
     "user_tz": 420
    },
    "id": "urCHgEWqQQvJ"
   },
   "outputs": [],
   "source": [
    "def show_data_results(X, y_pred=None, cmap='jet'):\n",
    "    if y_pred is None:\n",
    "        plt.scatter(X[:, 0], X[:, 1])\n",
    "        plt.title (\"input data\")\n",
    "    else:\n",
    "        fig = plt.figure(figsize=(10, 3))\n",
    "        ax1 = fig.add_subplot(121)\n",
    "        ax1.scatter(X[:, 0], X[:, 1])\n",
    "        ax1.set(xticks=[],yticks=[],title =\"input data\")\n",
    "\n",
    "        ax2 = fig.add_subplot(122)\n",
    "        ax2.scatter(X[:, 0], X[:, 1], c=y_pred, cmap=cmap)\n",
    "        ax2.set(xticks=[], yticks=[], title =\"clustered data\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "fGA8F3BzQQvK"
   },
   "source": [
    "# K-Means Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b8TiliOKQQvK"
   },
   "source": [
    "Please, read https://en.wikipedia.org/wiki/K-means_clustering about the Kmeans algorithm.\n",
    "\n",
    "In this problem, we will show how interperting a dataset as a graph may result is obtaining an elegant clustering solution. We have an input dataset that we wish to cluster in 3 aparant classes. \n",
    "\n",
    "We provide the synthetic dataset of 2000 points described below where the T_matrix is just a 2D transformation matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1664304108172,
     "user": {
      "displayName": "Jerome Quenum",
      "userId": "13777372482022053047"
     },
     "user_tz": 420
    },
    "id": "9UAZfB67QQvL"
   },
   "outputs": [],
   "source": [
    "n_samples, seed = 2000, 170\n",
    "X = get_data(n_samples, seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1664304108172,
     "user": {
      "displayName": "Jerome Quenum",
      "userId": "13777372482022053047"
     },
     "user_tz": 420
    },
    "id": "FdmYlJrAQQvL",
    "outputId": "c0a827d8-9ef9-4329-e127-0aac0c347ebc"
   },
   "outputs": [],
   "source": [
    "show_data_results(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7_h74XDHQQvM"
   },
   "source": [
    "Using the the Kmeans algorithm implementation of sklearn, show your attempt to cluster this dataset into 3 classes in one luine of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1664304112552,
     "user": {
      "displayName": "Jerome Quenum",
      "userId": "13777372482022053047"
     },
     "user_tz": 420
    },
    "id": "xytYbk3MQQvM"
   },
   "outputs": [],
   "source": [
    "y_pred = KMeans(n_clusters=3, random_state=seed).fit_predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 213
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1664304114177,
     "user": {
      "displayName": "Jerome Quenum",
      "userId": "13777372482022053047"
     },
     "user_tz": 420
    },
    "id": "eY4PoYWgQQvN",
    "outputId": "f81e7a1f-4788-4046-9233-bfe5306b27dc"
   },
   "outputs": [],
   "source": [
    "show_data_results(X, y_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "czyWZeIpQQvN"
   },
   "source": [
    "## Q.1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QLkM31wwQQvN"
   },
   "source": [
    "Comment on the output the the KMeans algorithm? Did it work? If so explain why, if not, explain not not."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "1J9M-KnsQQvO"
   },
   "source": [
    "## Q.2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kzFN2fngQQvO"
   },
   "source": [
    "Let's now interprete every single point in the provided dataset as a node in a graph. Our goal is to find a way to relate every node in the graph is such way that they points that closer together maintain that relationship while points that are far are explicitely identified. \n",
    "\n",
    "lots of points points are closed top each other and kmaeans is missing it. representing as the graph unveils the relation.\n",
    "\n",
    "One way to capture such relationship between points (nodes) in a graph is through the Adjacency matrix. Typically, a simple adjacency matrix between nodes of and indiredted graph is given by:\n",
    "\n",
    "$$A_{i, j}=\\begin{equation}\n",
    "\\left\\{ \n",
    "  \\begin{aligned}\n",
    "    1: \\text{if there is an edge between node i and node j}, \\\\\n",
    "    0: \\text{otherwise.}\\\\\n",
    "  \\end{aligned}\n",
    "  \\right.\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "In this probem, we will use the weighted distances betweeen points instead as a similary measure. Write a function that takes in the input dataset and some coeficient gamma which returns the adjacency matrix A.\n",
    "\n",
    "$$A_{i, j} = e^{\\gamma {||x_{i}-x_{j}||^2}}$$ \n",
    "\n",
    "where $x_{i}$ and $x_{j}$ represent each point in the provided dataset. You may find the `distance` module from `scipy.spatial` useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qBYsG_RXQQvO"
   },
   "outputs": [],
   "source": [
    "def get_adjacency_matrix(gamma, X):\n",
    "    # TODO: fill in your code here\n",
    "    # adjacency_matrix = ?\n",
    "    return adjacency_matrix"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "7wdTmZf5QQvP"
   },
   "source": [
    "## Q. 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7eODIZCuQQvP"
   },
   "source": [
    "The degree matrix of an undirected graph is a diagonal matrix which contains information about the degree of each vertex. In other word, it contains the number of edges attached to each vertex and it is given by:\n",
    "\n",
    "$$D_{i, j}=\\begin{equation}\n",
    "\\left\\{ \n",
    "  \\begin{aligned}\n",
    "    deg(v_{i}): \\text{if i == j}, \\\\\n",
    "    0: \\text{otherwise.}\\\\\n",
    "  \\end{aligned}\n",
    "  \\right.\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "where the degree $ {\\deg(v_{i})}$ of a vertex counts the number of times an edge terminates at that vertex. Note that in the traditional definition of the adjacency matrix, this boils down to the diagonal matrix in which element along the diagonals are column-wise sum of the adjacency matrix. Using the same idea, write a function that takes in the adjacency matrix as argument and returns the inverse square root of degree matrix.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pg8tpy99QQvP"
   },
   "outputs": [],
   "source": [
    "def get_degree_matrix(adjacency_matrix):\n",
    "    # TODO: fill in your code here\n",
    "    # degree_matrix = ?\n",
    "    return degree_matrix"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "A0qPciIpQQvQ"
   },
   "source": [
    "## Q. 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XmXY3B71QQvQ"
   },
   "source": [
    "Using $\\gamma$ = 7.5, compute the symmetrically normalized adjacency matrix A, degree matrix D and the matrix $M = D^{-1/2} A D^{-1/2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PVD-22vuQQvQ"
   },
   "outputs": [],
   "source": [
    "# adjacency_matrix = ?\n",
    "# degree_matrix = ?\n",
    "# M = ?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "JRL8XKn-QQvQ"
   },
   "source": [
    "## Q. 5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gRTb1CwnQQvQ"
   },
   "source": [
    "Using SVD decomposition, write a function that select the first 3 vectors in the matrix U and perform the same KMeans clustering used above to cluster them them. What do you observe? Did it work? If so explain why, if not, explain not not."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "ofnGUPi5QQvR"
   },
   "source": [
    "## Q.6. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jbsGjr5yQQvR"
   },
   "source": [
    "Now lets think of the Adjacency obtained above as the transition Matrix in of a Markov Chain.To do so, A needs to be a proper stochastic matrix which means that the sum of the element in each column must add up to 1. Write a function that takes in the matrix M and returns M_stachastic, the stochastic version of M; compute the stochastic matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6eXrjZTaQQvR"
   },
   "outputs": [],
   "source": [
    "def stochastic_matrix_converter(M):\n",
    "    # TODO: fill in your code here\n",
    "    # degree_matrix = ?\n",
    "    return M_stoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6Idj71eyQQvS"
   },
   "outputs": [],
   "source": [
    "M_stoch = stochastic_matrix_converter(M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j6piV8ziQQvS"
   },
   "source": [
    "perform the same KMeans clustering used above the resulting top 3 U vectors and plot your answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wjDhR_-WQQvS",
    "outputId": "7a7743e0-e8ee-4e03-fdfb-294e97e142b2"
   },
   "outputs": [],
   "source": [
    "y_pred_spectral_stoch = cluster_data(M_stoch)[1]\n",
    "show_data_results(X, y_pred_spectral_stoch)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "ofnGUPi5QQvR"
   },
   "source": [
    "## Q.7. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jbsGjr5yQQvR"
   },
   "source": [
    "Now, let's investigate how we could have made the matrix $M$ work directly in our original interpretation. To do this, normalize those 3 vectors before performing the clustering. \n",
    " **f{Show the plots. What do you observe? Did it work? If so, explain why normalizing the vectors gives what is expecte**d."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "c6e9dd8a8b6ec322311f321f91607e66d58649a44fea4cc269aee77bb59eb663"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
