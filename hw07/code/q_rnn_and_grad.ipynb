{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nraultwang/cs182/blob/main/hw07/code/q_rnn_and_grad.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yIqzcT6vyUJI"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "In this notebook, we'll implement simple RNNs and LSTMs, then explore how gradients flow through these different networks.\n",
        "\n",
        "This notebook does not require a Colab GPU. If it's enabled, you can turn it off through Runtime -> Change runtime type. (This will make it more likely for you to get Colab GPU access later in the REAL_RNN_LSTM.ipynb problem.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LL29FMhfyUJv"
      },
      "source": [
        "# Imports\n",
        "\n",
        "Note: the ipympl installation will require you to restart the colab runtime."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "n4YRmWnXe1-c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9821d4d7-b40f-493a-a506-6bccf14d576b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ipympl in /usr/local/lib/python3.12/dist-packages (0.9.8)\n",
            "Requirement already satisfied: ipython<10 in /usr/local/lib/python3.12/dist-packages (from ipympl) (7.34.0)\n",
            "Requirement already satisfied: ipywidgets<9,>=7.6.0 in /usr/local/lib/python3.12/dist-packages (from ipympl) (7.7.1)\n",
            "Requirement already satisfied: matplotlib<4,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from ipympl) (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from ipympl) (2.0.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from ipympl) (11.3.0)\n",
            "Requirement already satisfied: traitlets<6 in /usr/local/lib/python3.12/dist-packages (from ipympl) (5.7.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.12/dist-packages (from ipython<10->ipympl) (75.2.0)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.12/dist-packages (from ipython<10->ipympl) (0.19.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.12/dist-packages (from ipython<10->ipympl) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.12/dist-packages (from ipython<10->ipympl) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from ipython<10->ipympl) (3.0.52)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.12/dist-packages (from ipython<10->ipympl) (2.19.2)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.12/dist-packages (from ipython<10->ipympl) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.12/dist-packages (from ipython<10->ipympl) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.12/dist-packages (from ipython<10->ipympl) (4.9.0)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.12/dist-packages (from ipywidgets<9,>=7.6.0->ipympl) (6.17.1)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.12/dist-packages (from ipywidgets<9,>=7.6.0->ipympl) (0.2.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.12/dist-packages (from ipywidgets<9,>=7.6.0->ipympl) (3.6.10)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from ipywidgets<9,>=7.6.0->ipympl) (3.0.15)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4,>=3.5.0->ipympl) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4,>=3.5.0->ipympl) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4,>=3.5.0->ipympl) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4,>=3.5.0->ipympl) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4,>=3.5.0->ipympl) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4,>=3.5.0->ipympl) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4,>=3.5.0->ipympl) (2.9.0.post0)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.12/dist-packages (from ipykernel>=4.5.1->ipywidgets<9,>=7.6.0->ipympl) (1.8.15)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.12/dist-packages (from ipykernel>=4.5.1->ipywidgets<9,>=7.6.0->ipympl) (7.4.9)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.12/dist-packages (from ipykernel>=4.5.1->ipywidgets<9,>=7.6.0->ipympl) (1.6.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from ipykernel>=4.5.1->ipywidgets<9,>=7.6.0->ipympl) (5.9.5)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.12/dist-packages (from ipykernel>=4.5.1->ipywidgets<9,>=7.6.0->ipympl) (26.2.1)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.12/dist-packages (from ipykernel>=4.5.1->ipywidgets<9,>=7.6.0->ipympl) (6.5.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.12/dist-packages (from jedi>=0.16->ipython<10->ipympl) (0.8.5)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.12/dist-packages (from pexpect>4.3->ipython<10->ipympl) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython<10->ipympl) (0.2.14)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib<4,>=3.5.0->ipympl) (1.17.0)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.12/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (6.5.7)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.12/dist-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets<9,>=7.6.0->ipympl) (0.4)\n",
            "Requirement already satisfied: jupyter-core>=4.9.2 in /usr/local/lib/python3.12/dist-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets<9,>=7.6.0->ipympl) (5.9.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (3.1.6)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.12/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (25.1.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.12/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (5.10.4)\n",
            "Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.12/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (7.16.6)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.12/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.12/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (0.23.1)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.12/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (1.3.3)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.12/dist-packages (from jupyter-core>=4.9.2->jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets<9,>=7.6.0->ipympl) (4.5.0)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.12/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (0.2.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (4.13.5)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.12/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (6.2.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.12/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.12/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (0.3.0)\n",
            "Requirement already satisfied: markupsafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (3.0.3)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.12/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (3.1.4)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (0.10.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (1.5.1)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.12/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (2.21.2)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.12/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (4.25.1)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.12/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (25.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (1.4.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (0.27.1)\n",
            "Requirement already satisfied: jupyter-server<3,>=1.8 in /usr/local/lib/python3.12/dist-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (2.14.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (2.0.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (2.8)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (4.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (2.23)\n",
            "Requirement already satisfied: anyio>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (4.11.0)\n",
            "Requirement already satisfied: jupyter-events>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (0.12.0)\n",
            "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (0.5.3)\n",
            "Requirement already satisfied: overrides>=5.0 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (7.7.0)\n",
            "Requirement already satisfied: websocket-client>=1.7 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (1.9.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (3.11)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (1.3.1)\n",
            "Requirement already satisfied: python-json-logger>=2.0.4 in /usr/local/lib/python3.12/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (4.0.0)\n",
            "Requirement already satisfied: pyyaml>=5.3 in /usr/local/lib/python3.12/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (6.0.3)\n",
            "Requirement already satisfied: rfc3339-validator in /usr/local/lib/python3.12/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (0.1.4)\n",
            "Requirement already satisfied: rfc3986-validator>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (0.1.1)\n",
            "Requirement already satisfied: fqdn in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (1.5.1)\n",
            "Requirement already satisfied: isoduration in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (20.11.0)\n",
            "Requirement already satisfied: jsonpointer>1.13 in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (3.0.0)\n",
            "Requirement already satisfied: rfc3987-syntax>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (1.1.0)\n",
            "Requirement already satisfied: uri-template in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (1.3.0)\n",
            "Requirement already satisfied: webcolors>=24.6.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (24.11.1)\n",
            "Requirement already satisfied: lark>=1.2.2 in /usr/local/lib/python3.12/dist-packages (from rfc3987-syntax>=1.1.0->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (1.3.0)\n",
            "Requirement already satisfied: arrow>=0.15.0 in /usr/local/lib/python3.12/dist-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (1.3.0)\n",
            "Requirement already satisfied: types-python-dateutil>=2.8.10 in /usr/local/lib/python3.12/dist-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (2.9.0.20251008)\n"
          ]
        }
      ],
      "source": [
        "! pip install ipympl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "-G1WS5wsd2r4"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "\n",
        "# If you are not using colab you can delete these two lines\n",
        "from google.colab import output\n",
        "output.enable_custom_widget_manager()\n",
        "\n",
        "import torch as th\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from ipywidgets import interactive, widgets, Layout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Isyir7ROd20g"
      },
      "outputs": [],
      "source": [
        "%matplotlib ipympl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7WmHtmlVul1z"
      },
      "source": [
        "# 1.A: implementing a RNN layer\n",
        "\n",
        "Consider using Pytorch's [nn.Linear](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear). You can implement this with either one Linear layer or two. If you use two, remember that you only need to include a bias term for one of the linear layers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OXsJZLtepGYn"
      },
      "outputs": [],
      "source": [
        "class RNNLayer(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, nonlinearity=th.tanh):\n",
        "    \"\"\"\n",
        "    Initialize a single RNN layer.\n",
        "\n",
        "    Inputs:\n",
        "    - input_size: Data input feature dimension\n",
        "    - hidden_size: RNN hidden state size (also the output feature dimension)\n",
        "    - nonlinearity: Nonlinearity applied to the rnn output\n",
        "    \"\"\"\n",
        "    super().__init__()\n",
        "    self.input_size = input_size\n",
        "    self.hidden_size = hidden_size\n",
        "    self.nonlinearity = nonlinearity\n",
        "    ##############################################################################\n",
        "    # TODO: Initialize any parameters your class needs.                          #\n",
        "    ##############################################################################\n",
        "    ##############################################################################\n",
        "    #                               END OF YOUR CODE                             #\n",
        "    ##############################################################################\n",
        "\n",
        "  def forward(self, x):\n",
        "    \"\"\"\n",
        "    RNN forward pass\n",
        "\n",
        "    Inputs:\n",
        "    - x: input tensor (B, seq_len, input_size)\n",
        "\n",
        "    Returns:\n",
        "    - all_h: tensor of size (B, seq_len, hidden_size) containing hidden states\n",
        "             produced for each timestep\n",
        "    - last_h: hidden state from the last timestep (B, hidden_size)\n",
        "    \"\"\"\n",
        "    h_list = []  # List to store the hidden states [h_1, ... h_T]\n",
        "    ##############################################################################\n",
        "    # TODO: Implement the RNN forward step                                       #\n",
        "    # 1. Initialize h0 with zeros                                                #\n",
        "    # 2. Roll out the RNN over the sequence, storing hidden states in h_list     #\n",
        "    # 3. Return the appropriate outputs                                          #\n",
        "    ##############################################################################\n",
        "    ##############################################################################\n",
        "    #                               END OF YOUR CODE                             #\n",
        "    ##############################################################################\n",
        "\n",
        "    # h_list should now contain all hidden states, each of size (B, hidden_size)\n",
        "    # We will store the hidden states so we can analyze their gradients later\n",
        "    self.store_h_for_grad(h_list)\n",
        "    all_h = th.stack(h_list, dim=1)\n",
        "    return all_h, last_h\n",
        "\n",
        "  def store_h_for_grad(self, h_list):\n",
        "    \"\"\"\n",
        "    Store input list and allow gradient computation for all list elements\n",
        "    \"\"\"\n",
        "    for h in h_list:\n",
        "      h.retain_grad()\n",
        "    self.h_list = h_list\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usA4sa1CDzOs"
      },
      "source": [
        "### Test Cases\n",
        "\n",
        "If your implementation is correct, you should expect to see errors of less than 1e-4."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o6mwjkpMyt6n"
      },
      "outputs": [],
      "source": [
        "rnn = RNNLayer(1, 1)\n",
        "# Overwrite initial parameters with fixed values.\n",
        "# Should give deterministic results even with different implementations.\n",
        "rnn.load_state_dict({k: v * 0 + .1 for k, v in rnn.state_dict().items()})\n",
        "data = th.ones((1, 1, 1))\n",
        "expected_out = th.FloatTensor([[[0.1973753273487091]]])\n",
        "all_h, last_h = rnn(data)\n",
        "assert all_h.shape == expected_out.shape\n",
        "assert th.all(th.isclose(all_h, last_h))\n",
        "print(f'Expected: {expected_out.item()}, got: {last_h.item()}, max error: {th.max(th.abs(expected_out - last_h)).item()}')\n",
        "\n",
        "rnn = RNNLayer(2, 3, nonlinearity=lambda x: x)  # no nonlinearity\n",
        "\n",
        "num_params = sum(p.numel() for p in rnn.parameters())\n",
        "assert num_params == 18, f'expected 18 parameters but found {num_params}'\n",
        "\n",
        "rnn.load_state_dict({k: v * 0 - .1 for k, v in rnn.state_dict().items()})\n",
        "data = th.FloatTensor([[[.1, .15], [.2, .25], [.3, .35], [.4, .45]], [[-.1, -1.5], [-.2, -2.5], [-.3, -3.5], [-.4, -.45]]])\n",
        "expected_all_h = th.FloatTensor([[[-0.1250, -0.1250, -0.1250],\n",
        "         [-0.1075, -0.1075, -0.1075],\n",
        "         [-0.1328, -0.1328, -0.1328],\n",
        "         [-0.1452, -0.1452, -0.1452]],\n",
        "\n",
        "        [[ 0.0600,  0.0600,  0.0600],\n",
        "         [ 0.1520,  0.1520,  0.1520],\n",
        "         [ 0.2344,  0.2344,  0.2344],\n",
        "         [-0.0853, -0.0853, -0.0853]]])\n",
        "expected_last_h = th.FloatTensor([[-0.1452, -0.1452, -0.1452],\n",
        "        [-0.0853, -0.0853, -0.0853]])\n",
        "all_h, last_h = rnn(data)\n",
        "assert all_h.shape == expected_all_h.shape\n",
        "assert last_h.shape == expected_last_h.shape\n",
        "print(f'Max error all_h: {th.max(th.abs(expected_all_h - all_h)).item()}')\n",
        "print(f'Max error last_h: {th.max(th.abs(expected_last_h - last_h)).item()}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tbZtognVqQEO"
      },
      "source": [
        "# 1.B Implementing a RNN regression model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FFXhxs9UqQOS"
      },
      "outputs": [],
      "source": [
        "class RecurrentRegressionModel(nn.Module):\n",
        "  def __init__(self, recurrent_net, output_dim=1):\n",
        "    \"\"\"\n",
        "    Initialize a simple RNN regression model\n",
        "\n",
        "    Inputs:\n",
        "    - recurrent_net: an RNN or LSTM (single or multi layer)\n",
        "    - output_dim: feature dimension of the output\n",
        "    \"\"\"\n",
        "    super().__init__()\n",
        "    self.recurrent_net = recurrent_net\n",
        "    self.output_dim = output_dim\n",
        "    ##############################################################################\n",
        "    # TODO: Initialize any parameters you need                                   #\n",
        "    # HINT: use recurrent_net.hidden_size to find the hidden state size          #\n",
        "    ##############################################################################\n",
        "    ##############################################################################\n",
        "    #                               END OF YOUR CODE                             #\n",
        "    ##############################################################################\n",
        "\n",
        "  def forward(self, x):\n",
        "    \"\"\"\n",
        "    Forward pass\n",
        "\n",
        "    Inputs:\n",
        "    - x: input tensor (B, seq_len, input_size)\n",
        "\n",
        "    Returns:\n",
        "    - out: predictions of shape (B, seq_len, self.output_dim).\n",
        "    - all_h: tensor of size (B, seq_len, hidden_size) containing hidden states\n",
        "             produced for each timestep.\n",
        "    \"\"\"\n",
        "    ##############################################################################\n",
        "    # TODO: Implement the forward step.                                          #\n",
        "    ##############################################################################\n",
        "    ##############################################################################\n",
        "    #                               END OF YOUR CODE                             #\n",
        "    ##############################################################################\n",
        "    return out, all_h\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wHVeC-hCSA6S"
      },
      "source": [
        "## Tests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bWVnBJUbSBFP"
      },
      "outputs": [],
      "source": [
        "rnn = RecurrentRegressionModel(RNNLayer(2, 3), 4)\n",
        "\n",
        "num_params = sum(p.numel() for p in rnn.parameters())\n",
        "assert num_params == 34, f'expected 34 parameters but found {num_params}'\n",
        "\n",
        "rnn.load_state_dict({k: v * 0 - .1 for k, v in rnn.state_dict().items()})\n",
        "data = th.FloatTensor([[[.1, .15], [.2, .25], [.3, .35], [.4, .45]], [[-.1, -1.5], [-.2, -2.5], [-.3, -3.5], [-.4, -.45]]])\n",
        "expected_preds = th.FloatTensor([[[-0.0627, -0.0627, -0.0627, -0.0627],\n",
        "         [-0.0678, -0.0678, -0.0678, -0.0678],\n",
        "         [-0.0604, -0.0604, -0.0604, -0.0604],\n",
        "         [-0.0567, -0.0567, -0.0567, -0.0567]],\n",
        "\n",
        "        [[-0.1180, -0.1180, -0.1180, -0.1180],\n",
        "         [-0.1453, -0.1453, -0.1453, -0.1453],\n",
        "         [-0.1692, -0.1692, -0.1692, -0.1692],\n",
        "         [-0.0748, -0.0748, -0.0748, -0.0748]]])\n",
        "expected_all_h = th.FloatTensor([[[-0.1244, -0.1244, -0.1244],\n",
        "         [-0.1073, -0.1073, -0.1073],\n",
        "         [-0.1320, -0.1320, -0.1320],\n",
        "         [-0.1444, -0.1444, -0.1444]],\n",
        "\n",
        "        [[ 0.0599,  0.0599,  0.0599],\n",
        "         [ 0.1509,  0.1509,  0.1509],\n",
        "         [ 0.2305,  0.2305,  0.2305],\n",
        "         [-0.0840, -0.0840, -0.0840]]])\n",
        "preds, all_h = rnn(data)\n",
        "assert all_h.shape == expected_all_h.shape\n",
        "assert preds.shape == expected_preds.shape\n",
        "print(f'Max error all_h: {th.max(th.abs(expected_all_h - all_h)).item()}')\n",
        "print(f'Max error last_h: {th.max(th.abs(expected_preds - preds)).item()}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VC9LWlnOKyKi"
      },
      "source": [
        "# Problem 1.C: Dataset and loss function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZZ26gO5wYAH"
      },
      "source": [
        "## 1.C.i: Understanding the dataset (no implementation needed)\n",
        "\n",
        "Inspect the code and plots below to visualize the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VeJgsS0F_p8Q"
      },
      "outputs": [],
      "source": [
        "def generate_batch(seq_len=10, batch_size=1):\n",
        "  data = th.randn(size=(batch_size, seq_len, 1))\n",
        "  sums = th.cumsum(data, dim=1)\n",
        "  div = (th.arange(seq_len) + 1).unsqueeze(0).unsqueeze(2)\n",
        "  target = sums / div\n",
        "  return data, target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q7iiiEsV_67L"
      },
      "outputs": [],
      "source": [
        "x, y = generate_batch(seq_len=10, batch_size=4)\n",
        "for i in range(4):\n",
        "  fig, ax1 = plt.subplots(1)\n",
        "  ax1.plot(x[i, :, 0])\n",
        "  ax1.plot(y[i, :, 0])\n",
        "  ax1.legend(['x', 'y'])\n",
        "  plt.title('Targets at all timesteps')\n",
        "  plt.show()\n",
        "\n",
        "for i in range(4):\n",
        "  fig, ax1 = plt.subplots(1)\n",
        "  ax1.plot(x[i, :, 0])\n",
        "  ax1.plot(np.arange(10), [y[i, -1].item()] * 10)\n",
        "  ax1.legend(['x', 'y'])\n",
        "  plt.title('Predict only at the last timestep')\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLLCIL7iH4CE"
      },
      "source": [
        "## 1.C.ii Implement the loss function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X2g0Nc4SVIjS"
      },
      "outputs": [],
      "source": [
        "def loss_fn(pred, y, last_timestep_only=False):\n",
        "  \"\"\"\n",
        "  Inputs:\n",
        "  - pred: model predictions of size (batch, seq_len, 1)\n",
        "  - y: targets of size (batch, seq_len, 1)\n",
        "  - last_timestep_only: boolean indicating whether to compute loss for all\n",
        "    timesteps or only the lat\n",
        "\n",
        "  Returns:\n",
        "  - loss: scalar MSE loss between pred and true labels\n",
        "  \"\"\"\n",
        "  ##############################################################################\n",
        "  # TODO: implement the loss (HINT: look for pytorch's MSELoss function)       #\n",
        "  ##############################################################################\n",
        "  ##############################################################################\n",
        "  #                               END OF YOUR CODE                             #\n",
        "  ##############################################################################\n",
        "  return loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLV9IqVOWnoC"
      },
      "source": [
        "### Tests\n",
        "You should see errors < 1e-4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jP9pnOItWoFA"
      },
      "outputs": [],
      "source": [
        "pred = th.FloatTensor([[.1, .2, .3], [.4, .5, .6]])\n",
        "y = th.FloatTensor([[-1.1, -1.2, -1.3], [-1.4, -1.5, -1.6]])\n",
        "loss_all = loss_fn(pred, y, last_timestep_only=False)\n",
        "loss_last = loss_fn(pred, y, last_timestep_only=True)\n",
        "assert loss_all.shape == loss_last.shape == th.Size([])\n",
        "print(f'Max error loss_all: {th.abs(loss_all - th.tensor(3.0067)).item()}')\n",
        "print(f'Max error loss_last: {th.abs(loss_last - th.tensor(3.7)).item()}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OiNUuKSw3glG"
      },
      "source": [
        "# 1.D: Analyzing RNN Gradients"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GaaGVQyejUjE"
      },
      "source": [
        "You do not need to understand the details of the GradientVisualizer class in order to complete this problem."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N80gvsMvK78G"
      },
      "outputs": [],
      "source": [
        "def biggest_eig_magnitude(matrix):\n",
        "  \"\"\"\n",
        "  Inputs: a square matrix\n",
        "  Returns: the scalar magnitude of the largest eigenvalue\n",
        "  \"\"\"\n",
        "  h, w = matrix.shape\n",
        "  assert h == w, f'Matrix has shape {matrix.shape}, but eigenvalues can only be computed for square matrices'\n",
        "  eigs = th.linalg.eigvals(matrix)\n",
        "  eig_magnitude = eigs.abs()\n",
        "  eigs_sorted = sorted([i.item() for i in eig_magnitude], reverse=True)\n",
        "  first_eig_magnitude = eigs_sorted[0]\n",
        "  return first_eig_magnitude\n",
        "\n",
        "class GradientVisualizer:\n",
        "\n",
        "  def __init__(self, rnn, last_timestep_only):\n",
        "    \"\"\"\n",
        "    Inputs:\n",
        "    - rnn: rnn module\n",
        "    - last_timestep_only: boolean indicating whether to compute loss for all\n",
        "      timesteps or only the lat\n",
        "\n",
        "    Returns:\n",
        "    - loss: scalar MSE loss between pred and true labels\n",
        "    \"\"\"\n",
        "\n",
        "    self.rnn = rnn\n",
        "    self.last_timestep_only = last_timestep_only\n",
        "    self.model = RecurrentRegressionModel(rnn)\n",
        "    self.original_weights = copy.deepcopy(rnn.state_dict())\n",
        "\n",
        "    # Generate a single batch to be used repeatedly\n",
        "    self.x, self.y = generate_batch(seq_len=10)\n",
        "    print(f'Data point: x={np.round(self.x[0, :, 0].detach().cpu().numpy(), 2)}, y={np.round(self.y.squeeze().detach().cpu().numpy(), 2)}')\n",
        "\n",
        "  def plot_visuals(self):\n",
        "    \"\"\" Generate plots which will be updated in realtime.\"\"\"\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2)\n",
        "    ax1.set_title('RNN Outputs')\n",
        "    ax1.set_xlabel('Unroll Timestep')\n",
        "    ax1.set_ylabel('Hidden State Norm')\n",
        "    ax1.set_ylim(-1, 5)\n",
        "    plt_1 = ax1.plot(np.arange(1, 11), np.zeros(10) + 1)  # placeholder vals\n",
        "    plt_1 = plt_1[0]\n",
        "\n",
        "    ax2.set_title('Gradients')\n",
        "    ax2.set_xlabel('Unroll Timestep')\n",
        "    ax2.set_ylabel('RNN dLoss/d a_t Gradient Magitude')\n",
        "    ax2.set_ylim( (10**-6,1e5) )\n",
        "    ax2.set_yscale('log')\n",
        "    # X-axis labels are reversed since the gradient flow is from later layers to earlier layers\n",
        "    ax2.set_xticks(np.arange(10), np.arange(10, 0, -1))\n",
        "    plt_2 = ax2.plot(np.arange(10), np.arange(10) + 1)  # placeholder vals\n",
        "    plt_2 = plt_2[0]\n",
        "    self.fig = fig\n",
        "    self.plots = [plt_1, plt_2]\n",
        "    return plt_1, plt_2, fig\n",
        "\n",
        "  # Main update function for interactive plot\n",
        "  def update_plots(self, weight_val=0, bias_val=0):\n",
        "    # Scale the original RNN weights by a constant\n",
        "    w_dict = copy.deepcopy(self.original_weights)\n",
        "    ##############################################################################\n",
        "    # TODO: Scale all W matrixes by weight_val, and all bias matrices by bias_val#\n",
        "    # If you're using PyTorch nn.Linear layers, you don't need to modify the code#\n",
        "    # provided, but if you're using custom layers, modify this block.            #\n",
        "    ##############################################################################\n",
        "    ##############################################################################\n",
        "    #                               END OF YOUR CODE                             #\n",
        "    ##############################################################################\n",
        "    self.rnn.load_state_dict(w_dict)\n",
        "\n",
        "    # Don't compute for LSTMs, which don't have behavior dependent on a single eigenvalue\n",
        "    if isinstance(self.rnn, RNNLayer):\n",
        "      ##############################################################################\n",
        "      # TODO: Set W = the weight which most affects exploding/vanishing gradients  #\n",
        "      # Hint: Call module.weight or module.bias on the module you want to use      #\n",
        "      # If you used a single Linear layer, slice a square matrix from it.          #\n",
        "      ##############################################################################\n",
        "      ##############################################################################\n",
        "      #                               END OF YOUR CODE                             #\n",
        "      ##############################################################################\n",
        "      biggest_eig = biggest_eig_magnitude(W)\n",
        "      print(f' Biggest eigenvalue magnitude: {biggest_eig:.3}')\n",
        "\n",
        "    # Run model\n",
        "    pred, h = self.model(self.x)\n",
        "    loss = loss_fn(pred, self.y, self.last_timestep_only)\n",
        "    n_steps = len(h[0])\n",
        "\n",
        "    plt_1, plt_2 = self.plots\n",
        "\n",
        "    # Plot the hidden state magnitude\n",
        "    max_h = th.linalg.norm(h[0], dim=-1).detach().cpu().numpy()\n",
        "    print('Max H', ' '.join([f'{num:.3}' for num in max_h]))\n",
        "    plt_1.set_data(np.arange(1, n_steps + 1), np.array(max_h))\n",
        "    # Compute the gradient for the loss wrt the stored hidden states\n",
        "    # Gradients are plotted backward since we go from later layers to earlier\n",
        "    grads = [th.linalg.norm(num).item() for num in th.autograd.grad(loss, self.rnn.h_list)][::-1]\n",
        "    print('gradients d Loss/d h_t', ' '.join([f'{num:.3}' for num in grads]))\n",
        "    # Add 1e-6 since it throws an error for gradients near 0\n",
        "    plt_2.set_data(np.arange(n_steps), np.array(grads) + 1e-6)\n",
        "    self.fig.canvas.draw_idle()\n",
        "\n",
        "  def create_visualization(self):\n",
        "    # Include sliders for relevant quantities\n",
        "    self.plot_visuals()\n",
        "    ip = interactive(self.update_plots,\n",
        "                    weight_val=widgets.FloatSlider(value=0, min=-5, max=5, step=.05, description=\"weight_scale\", layout=Layout(width='100%')),\n",
        "                    bias_val=widgets.FloatSlider(value=0, min=-5, max=5, step=.05, description=\"bias_scale\", layout=Layout(width='100%')),\n",
        "                    )\n",
        "    return ip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OiTaiihtZb_q"
      },
      "source": [
        "Adjust the sliders rescale the weight and bias parameters in the RNN. Observe the effect on exploding and vanishing gradients.\n",
        "\n",
        "Parameters to try varying:\n",
        "*   nonlinearity\n",
        "*   last_target_only\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3G_B0NEvEAAp"
      },
      "outputs": [],
      "source": [
        "hidden_size = 16\n",
        "nonlinearity = lambda x: x  # options include lambda x: x (no nonlinearity), nn.functional.relu, and th.tanh\n",
        "last_target_only = True\n",
        "rnn = RNNLayer(1, hidden_size, nonlinearity=nonlinearity)\n",
        "gv = GradientVisualizer(rnn, last_target_only)\n",
        "gv.create_visualization()\n",
        "\n",
        "# If for some reason the slider doesn't work for you, try calling gv.update_plots\n",
        "# with various values for weight and bias"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mAhVHPaEy4x8"
      },
      "source": [
        "# Problem 1.K: Making a multi-layer RNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "doMWE3eeouQE"
      },
      "source": [
        "## 1.K.i: Implementing multi-layer models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ns8-s9-MMInz"
      },
      "outputs": [],
      "source": [
        "class RNN(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, num_layers):\n",
        "    \"\"\"\n",
        "    Initialize a multilayer RNN\n",
        "\n",
        "    Inputs:\n",
        "    - input_size: Data input feature dimension\n",
        "    - hidden_size: hidden state size (also the output feature dimension)\n",
        "    - num_layers: number of layers\n",
        "    \"\"\"\n",
        "    super().__init__()\n",
        "    assert num_layers >= 1\n",
        "    self.input_size = input_size\n",
        "    self.hidden_size = hidden_size\n",
        "    self.num_layers = num_layers\n",
        "    ##############################################################################\n",
        "    # TODO: Initialize any parameters your class needs.                          #\n",
        "    # Consider using nn.ModuleList or nn.ModuleDict.                             #\n",
        "    ##############################################################################\n",
        "    ##############################################################################\n",
        "    #                               END OF YOUR CODE                             #\n",
        "    ##############################################################################\n",
        "\n",
        "  def forward(self, x):\n",
        "    \"\"\"\n",
        "    Multilayer RNN forward pass\n",
        "\n",
        "    Inputs:\n",
        "    - x: input tensor (B, seq_len, input_size)\n",
        "\n",
        "    Returns:\n",
        "    - last_layer_h: tensor of size (B, seq_len, hidden_size) containing the\n",
        "             outputs produced for each timestep from the last layer\n",
        "    - last_step_h: all hidden states from the last step (num_layers, B, hidden_size)\n",
        "    \"\"\"\n",
        "    ##############################################################################\n",
        "    # TODO: Implement the RNN forward step                                       #\n",
        "    ##############################################################################\n",
        "    ##############################################################################\n",
        "    #                               END OF YOUR CODE                             #\n",
        "    ##############################################################################\n",
        "    return last_layer_h, last_step_h"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8o2noEJyN8c0"
      },
      "source": [
        "### Test Cases"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5mskU70eN8mq"
      },
      "outputs": [],
      "source": [
        "rnn = RNN(2, 3, 1)\n",
        "rnn.load_state_dict({k: v * 0 - .1 for k, v in rnn.state_dict().items()})\n",
        "data = th.FloatTensor([[[.1, .15], [.2, .25], [.3, .35], [.4, .45]], [[-.1, -1.5], [-.2, -2.5], [-.3, -3.5], [-.4, -.45]]])\n",
        "expected_all_h = th.FloatTensor([[[-0.1244, -0.1244, -0.1244],\n",
        "         [-0.1073, -0.1073, -0.1073],\n",
        "         [-0.1320, -0.1320, -0.1320],\n",
        "         [-0.1444, -0.1444, -0.1444]],\n",
        "\n",
        "        [[ 0.0599,  0.0599,  0.0599],\n",
        "         [ 0.1509,  0.1509,  0.1509],\n",
        "         [ 0.2305,  0.2305,  0.2305],\n",
        "         [-0.0840, -0.0840, -0.0840]]])\n",
        "expected_last_h = th.FloatTensor([[[-0.1444, -0.1444, -0.1444],\n",
        "         [-0.0840, -0.0840, -0.0840]]])\n",
        "all_h, last_h = rnn(data)\n",
        "assert all_h.shape == expected_all_h.shape\n",
        "assert last_h.shape == expected_last_h.shape\n",
        "print(f'Max error all_h: {th.max(th.abs(expected_all_h - all_h)).item()}')\n",
        "print(f'Max error last_h: {th.max(th.abs(expected_last_h - last_h)).item()}')\n",
        "\n",
        "rnn = RNN(2, 3, 2)\n",
        "rnn.load_state_dict({k: v * 0 - .1 for k, v in rnn.state_dict().items()})\n",
        "data = th.FloatTensor([[[.1, .15], [.2, .25], [.3, .35], [.4, .45]], [[-.1, -1.5], [-.2, -2.5], [-.3, -3.5], [-.4, -.45]]])\n",
        "expected_all_h = th.FloatTensor([[[-0.0626, -0.0626, -0.0626],\n",
        "         [-0.0490, -0.0490, -0.0490],\n",
        "         [-0.0457, -0.0457, -0.0457],\n",
        "         [-0.0430, -0.0430, -0.0430]],\n",
        "        [[-0.1174, -0.1174, -0.1174],\n",
        "         [-0.1096, -0.1096, -0.1096],\n",
        "         [-0.1354, -0.1354, -0.1354],\n",
        "         [-0.0342, -0.0342, -0.0342]]])\n",
        "expected_last_h = th.FloatTensor([[[-0.1444, -0.1444, -0.1444],\n",
        "         [-0.0840, -0.0840, -0.0840]],\n",
        "        [[-0.0430, -0.0430, -0.0430],\n",
        "         [-0.0342, -0.0342, -0.0342]]])\n",
        "all_h, last_h = rnn(data)\n",
        "assert all_h.shape == (2, 4, 3)\n",
        "assert last_h.shape == (2, 2, 3)\n",
        "print(f'Max error all_h: {th.max(th.abs(expected_all_h - all_h)).item()}')\n",
        "print(f'Max error last_h: {th.max(th.abs(expected_last_h - last_h)).item()}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQriJsNirJp2"
      },
      "source": [
        "## 1.K.ii: Training your model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4O5rRLJTrI-A"
      },
      "outputs": [],
      "source": [
        "def train(model, optimizer, num_batches, last_timestep_only, seq_len=10, batch_size=32):\n",
        "  model\n",
        "  model.train()\n",
        "\n",
        "  losses = []\n",
        "  from tqdm import tqdm\n",
        "  t = tqdm(range(0, num_batches))\n",
        "  for i in t:\n",
        "      data, labels = generate_batch(seq_len=seq_len, batch_size=batch_size)\n",
        "      pred, h = model(data)\n",
        "      loss = loss_fn(pred, labels, last_timestep_only)\n",
        "      losses.append(loss.item())\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      if i % 100 == 0:\n",
        "          t.set_description(f\"Batch: {i} Loss: {np.mean(losses[-10:])}\")\n",
        "  return losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vlkbHdA_r-1N"
      },
      "outputs": [],
      "source": [
        "def train_all(hidden_size, lr, num_batches, last_timestep_only):\n",
        "  input_size = 1\n",
        "  rnn_1_layer = RecurrentRegressionModel(RNN(input_size, hidden_size, 1))\n",
        "  rnn_2_layer = RecurrentRegressionModel(RNN(input_size, hidden_size, 2))\n",
        "  models = [rnn_1_layer, rnn_2_layer]\n",
        "  model_names = ['rnn_1_layer', 'rnn_2_layer']\n",
        "\n",
        "  losses = []\n",
        "  for model in models:\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "    loss = train(model, optimizer, num_batches, last_timestep_only)\n",
        "    losses.append(loss)\n",
        "\n",
        "  # visualize the results\n",
        "  fig, ax1 = plt.subplots(1)\n",
        "  for loss in losses:\n",
        "    ax1.plot(loss)\n",
        "  ax1.legend(model_names)\n",
        "  plt.show()\n",
        "\n",
        "  batch_size = 4\n",
        "  x, y = generate_batch(seq_len=10, batch_size=batch_size)\n",
        "  preds_list = [model(x)[0] for model in models]\n",
        "  for i in range(batch_size):\n",
        "    fig, ax1 = plt.subplots(1)\n",
        "    ax1.plot(x[i, :, 0])\n",
        "    if last_timestep_only:\n",
        "      ax1.plot(np.arange(10), [y[i, -1].item()] * 10, 'bo')\n",
        "    else:\n",
        "      ax1.plot(y[i, :, 0], 'bo')\n",
        "    for pred in preds_list:\n",
        "      if last_timestep_only:\n",
        "        ax1.plot(np.arange(10), [pred[i, -1, 0].detach().cpu().numpy()] * 10)\n",
        "      else:\n",
        "        ax1.plot(pred[i, :, 0].detach().cpu().numpy())\n",
        "    ax1.legend(['x', 'y'] + model_names)\n",
        "    plt.show()\n",
        "  return models, losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1HNCFFiRyere"
      },
      "outputs": [],
      "source": [
        "hidden_size = 32\n",
        "lr = 1e-4\n",
        "num_batches = 5000\n",
        "last_timestep_only = False\n",
        "\n",
        "th.manual_seed(0)\n",
        "predict_all_models, predict_all_losses = train_all(hidden_size, lr, num_batches, last_timestep_only)\n",
        "last_timestep_only = True\n",
        "predict_one_models, predict_one_losses = train_all(hidden_size, lr, num_batches, last_timestep_only)"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "colab": {
      "collapsed_sections": [
        "7WmHtmlVul1z",
        "usA4sa1CDzOs",
        "tbZtognVqQEO",
        "wHVeC-hCSA6S",
        "VC9LWlnOKyKi",
        "bZZ26gO5wYAH",
        "GLLCIL7iH4CE",
        "OLV9IqVOWnoC",
        "7qPcibFiyVsk",
        "30VuigbiL-7O",
        "Fj0Vf8l_yn9L",
        "doMWE3eeouQE",
        "8o2noEJyN8c0"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}